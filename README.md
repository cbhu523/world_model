# world_model
object-centric world model


# Awesome Object-Centric Counterfactual World Models (OCCWM)

A curated list of papers and resources on **Object-Centric Counterfactual World Models**,
covering world models, object-centric representations, causal and counterfactual reasoning,
benchmarks, and implementations.

> This repository is a companion to the survey  
> **"Object-Centric Counterfactual World Models: Foundations, Methods, and Recent Advances"**.

---

## Table of Contents

- [Foundations](#foundations)
- [Core OCCWM Methods](#core-occwm-methods)
- [Methods by Benchmark](#methods-by-benchmark)
- [Benchmarks and Datasets](#benchmarks-and-datasets)
- [Libraries and Tooling](#libraries-and-tooling)
- [Surveys and Related Awesome Lists](#surveys-and-related-awesome-lists)

---

## Foundations

### World Models
- [2018] Ha & Schmidhuber – *World Models* (arXiv:1803.10122)  
- [2019] Hafner et al. – *Dream to Control: Learning Behaviors by Latent Imagination* (Dreamer)

## Object-Centric World Models
### Table 1. Recent Object-Centric World Models (OCWM, ~2019–2025)

## Object-Centric World Models (OCWM) — Papers & Code

| Year | Paper Title | Code |
|------|-------------|------|
| 2019 | [SCALOR: Generative World Models with Scalable Object-Centric Representations](https://arxiv.org/abs/1910.02384) | – |
| 2019 | [C-SWM: Contrastive Learning of Structured World Models](https://arxiv.org/abs/1911.12247) | [Link](https://github.com/tkipf/c-swm)|
| 2020 | [G-SWM: Improving Generative Imagination in Object-Centric World Models](https://arxiv.org/abs/2007.09571) | [Link](https://github.com/zhixuan-lin/G-SWM) |
| 2020 | [OP3: Object-Oriented Perception, Prediction, and Planning](https://arxiv.org/abs/2007.05309) | [Link](https://github.com/jcoreyes/OP3) |
| 2020 | [SILOT: Spatially Invariant Learning of Object Tracking](https://arxiv.org/abs/2001.04918) | [Link](https://github.com/e2crawfo/silot) |
| 2021 | [SAVi: Conditional Object-Centric Learning from Video](https://arxiv.org/abs/2111.13723) | [Link](https://github.com/google-research/slot-attention-video) |
| 2022 | [SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos](https://arxiv.org/abs/2206.07764) | – |
| 2022 | [SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models](https://arxiv.org/abs/2210.05861) | [Link](https://github.com/pairlab/SlotFormer) |
| 2023 | [SlotDiffusion: Object-Centric Generative Modeling with Diffusion Models](https://arxiv.org/abs/2305.11281) | [Link](https://github.com/Wuziyi616/SlotDiffusion) |
| 2023 | [VideoSAUR: Object-Centric Learning for Real-World Videos](https://arxiv.org/abs/2306.04829) | [Link](https://github.com/martius-lab/videosaur) |
| 2024 | [Learning Physical Dynamics for Object-Centric Visual Prediction](https://arxiv.org/abs/2403.10079) | – |
| 2025 | [Dyn-O: Structured Object-Centric World Models](https://arxiv.org/abs/2503.02161) | [Link](https://github.com/wangzizhao/dyn-o) |
| 2025 | [SlotPi: Physics-informed Object-Centric Reasoning](https://arxiv.org/abs/2506.10778) | – |
| 2025 | [FOCUS: Object-Centric World Models for Robotic Manipulation](https://arxiv.org/abs/2310.19586) | [Link](https://github.com/StefanoFerraro/FOCUS) |

## Counterfactual World Models (CF-WM)

| Year | Paper Title | Code |
|------|-------------|------|
| 2021 | [Counterfactual Generative Networks (CGN)](https://arxiv.org/abs/2101.06046) | [Link](https://github.com/autonomousvision/counterfactual_generative_networks) |
| 2023 | [CWM: Unifying (Machine) Vision via Counterfactual World Modeling](https://arxiv.org/abs/2306.01828) | [Link](https://github.com/neuroailab/CounterfactualWorldModels) |
| 2024 | [CWM-Physics: Understanding Physical Dynamics with Counterfactual World Modeling](https://arxiv.org/abs/2312.06721) | [Link](https://github.com/rahulvenkk/cwm_dynamics) |
| 2025 | [Opt-CWM: Learning Motion Concepts by Optimizing Counterfactuals](https://arxiv.org/abs/2503.19953) | [Link](https://github.com/neuroailab/Opt_CWM) |
| 2025 | [KL-Tracing: Zero-Shot Optical Flow via Counterfactual Tracing](https://arxiv.org/abs/2507.09082) | [Link](https://neuroailab.github.io/projects/kl_tracing/) |
| 2025 | [Point Prompting: Counterfactual Tracking with Video Diffusion Models](https://arxiv.org/abs/2510.11715) | [Link](https://point-prompting.github.io) |
| 2025 | [CWMDT: Digital Twin-conditioned Counterfactual Video Diffusion](https://arxiv.org/abs/2511.17481) | – |
| 2025 | [Intuitive Physics via JEPA Pretraining](https://arxiv.org/abs/2502.11831) | [Link](https://github.com/facebookresearch/jepa-intuitive-physics) |

## Object-Centric Counterfactual World Models — Papers & Code

| Year | Paper Title | Code |
|------|------------------------|-----------|
| 2020 | [G-SWM: Improving Generative Imagination in Object-Centric World Models](https://arxiv.org/pdf/2010.02054) | [Link](https://github.com/zhixuan-lin/G-SWM) |
| 2020 | [CLEVRER: A Diagnostic Dataset for Video Reasoning](https://arxiv.org/abs/1910.01442) | [Link](https://github.com/chuangg/CLEVRER)|
| 2021 | [Physion: Evaluating Physical Prediction from Vision in Humans and Machines](https://arxiv.org/abs/2106.08261) | [Link](https://github.com/cogtoolslab/physics-benchmarking-neurips2021)|
| 2023 | [Unifying (Machine) Vision via Counterfactual World Modeling](https://arxiv.org/pdf/2306.01828) | [Link](https://github.com/neuroailab/CounterfactualWorldModels) |
| 2023 | [SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models](https://arxiv.org/abs/2210.05861) | [Link](https://github.com/pairlab/SlotFormer) |
| 2023 | [SlotDiffusion: Object-Centric Generative Modeling with Diffusion Models](https://arxiv.org/abs/2305.11281) | [Link](https://github.com/Wuziyi616/SlotDiffusion) |
| 2024 | [Understanding Physical Dynamics with Counterfactual World Modeling](https://arxiv.org/abs/2312.06721) | [Link](https://github.com/neuroailab/cwm_dynamics) |
| 2024 | [Object-Centric Temporal Consistency via Conditional Autoregressive Inductive Biases](https://arxiv.org/abs/2410.15728) | [Link](https://github.com/Cmeo97/CA-SA) |
| 2024 | [COIL: UNSUPERVISED OBJECT INTERACTION LEARNING WITH COUNTERFACTUAL DYNAMICS MODELS](https://openreview.net/pdf?id=dYjH8Nv81K) | None |
| 2025 | [Intuitive physics understanding emerges from self-supervised pretraining on natural videos](https://arxiv.org/abs/2502.11831) | [Link](https://github.com/facebookresearch/jepa-intuitive-physics) |
| 2025 | [CWMDT: Counterfactual World Modeling with Digital Twins-conditioned Video Diffusion](https://arxiv.org/pdf/2511.17481)| None |



### Causal and Counterfactual Foundations
- [2009] Pearl – *Causality* (book)  
- [2021] Schölkopf et al. – *Toward Causal Representation Learning*  
- [2024] Komanduri et al. – *From Identifiable Causal Representations to Controllable Counterfactual Generation*

---

## Core OCCWM Methods

### Vision Counterfactual World Models
- [2023] Bear et al. – *Unifying (Machine) Vision via Counterfactual World Modeling (CWM)*  
  - type: CF-WM, mask-based; domain: vision; bench: CLEVR-like, Physion-style  
- [2023] Venkatesh et al. – *Understanding Physical Dynamics with Counterfactual World Modeling*  
  - type: CF-WM for physics; bench: Physion

### Object-Centric World Models with Interventions
- [2020] G-SWM – *Improving Generative Imagination in Object-Centric World Models*  
- [2019] OP3 – *Entity Abstraction in Visual Model-Based RL*  

(… more entries …)

---

## Methods by Benchmark

### CLEVRER
- G-SWM (object-centric WM, synthetic physics)
- CWM (CF-WM with structured masking)
- ...

### Physion
- Physical CWM
- ...

### Kubric / MOVi
- Slot Attention
- DINOSAUR, SAVi++, VideoSAUR
- ...

(… continue for PHYRE, IntPhys, CausalWorld …)

---

## Benchmarks and Datasets
- CLEVRER – counterfactual video QA  
- Physion – intuitive physics prediction  
- PHYRE – physics+planning puzzles  
- Kubric / MOVi – synthetic video scenes with object GT  
- IntPhys / IntPhys2 – possible vs impossible physics  
- CausalWorld – robotic manipulation with do-interventions  

---

## Libraries and Tooling
- object-centric-library – OC models under distribution shifts  
- Awesome-World-Models, Awesome-World-Models-for-robots, etc. (related lists)

---

## Surveys and Related Awesome Lists
- Hitchhiker's Guide to World Models (paper + GitHub)  
- Awesome-World-Models (general)  
- Awesome-Causal-Learning / Awesome-Causality-in-CV  
